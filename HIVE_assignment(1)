# #Q(1): List directories / filesin HDFS; Copy files from LinuxFile System to HDFS: Copy files from HDFS to Linux File System

hdfs dfs -ls
hdfs dfs -put
hdfs dfs -get


## Q(2): In your hdfs homefolder(/user/<your-id>), create a folder named banklist,and copy /data/banklist/banklist.csv to the banklistfolder you just created

hdfs dfs -mkdir /user/kuanbaker/banklist
hdfs dfs -cp /data/banklist/banklist.csv banklist/

## Q(3): In your database,createa Hive managed table usingthe CSVfiles

CREATE TABLE IF NOT EXISTS kuan_db.banklist(
  bankname string,
	city string,
	state string,
	cert int,
	acquiring_institution string,
	closing_date string
)
ROW FORMAT SERDE
"org.apache.hadoop.hive.serde2.OpenCSVSerde"
WITH SERDEPROPERTIES(
 "separatorChar" = ",",
 "quoteChar" = "\"",
 "escapeChar" = "\\"
)
STORED AS textfile
TBLPROPERTIES("skip.header.line.count"="1");

LOAD DATA INPATH "/user/kuanbaker/banklist" INTO TABLE kuan_db.banklist;


## Q(4): create a Hive external table using the CSV files.

CREATE EXTERNAL TABLE IF NOT EXISTS kuan_db.banklist(
  bankname string,
	city string,
	state string,
	cert int,
	acquiring_institution string,
	closing_date string
)
ROW FORMAT SERDE
"org.apache.hadoop.hive.serde2.OpenCSVSerde"
WITH SERDEPROPERTIES(
  "separatorChar" = ",",
  "quoteChar" = "\"",
  "escapeChar" = "\\"
)
STORED AS textfile
LOCATION "/user/kuanbaker/banklist"
TBLPROPERTIES("skip.header.line.count" = "1");


## Q(5): Create a Hive table using AVRO file where you get from the SQOOP homework.


CREATE TABEL IF NOT EXISTS kuan_db.orders(
  order_id int,
  order_name string,
  order_description string
)
STORED AS avrodatafile;

LOAD DATA INPATH "/user/kuanbaker/sqoopimport/retail_db/avro/orders/*.avro"

